# Data Engineering Portfolio 🚀

Welcome to my personal data engineering portfolio! This repository showcases my learning journey and hands-on projects as I transition from an ETL Developer (Informatica) to a Data Engineer.

## 📌 Tech Stack
- SQL (LeetCode + Real-world scenarios)
- Python for ETL, scripting, and automation
- PySpark for scalable data processing
- Databricks notebooks and Delta Lake
- Microsoft Fabric (Power BI + Data Pipelines)

## 🔍 Project Highlights
| Project | Tech Used | Description |
|--------|------------|-------------|
| [Customer Churn Pipeline](./pyspark-projects/customer_churn_pipeline) | PySpark, Pandas | Scalable pipeline for customer churn data |
| [Sales ETL - Databricks](./databricks-notebooks/product_sales_etl) | Databricks, Delta Lake | End-to-end ETL of sales data |
| [SQL Practice](./sql-practice) | SQL | 50+ LeetCode problems with documented solutions |

## 📂 Folder Structure
- `sql-practice`: My solutions to SQL problems (mainly LeetCode).
- `python-projects`: Scripts for automation, cleaning, and transformation.
- `pyspark-projects`: Scalable data pipelines.
- `databricks-notebooks`: Real-world style notebooks.
- `microsoft-fabric`: Analytics dashboards and dataflows (Power BI).
- `datasets`: Public dataset references or scripts to fetch data.

## 📫 Contact
- LinkedIn: [advaith-koushik-s](https://www.linkedin.com/in/advaith-koushik-s/)
- Email: advai97@gmail.com

